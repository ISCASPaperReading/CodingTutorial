{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71479bb9-2371-4e58-a632-f485b493dac8",
   "metadata": {},
   "source": [
    "# Pytorch基本训练框架"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca39f0-c310-41ec-9bae-657a202f249a",
   "metadata": {},
   "source": [
    "## 基本组件1: 神经网络\n",
    "1. 所有的Pytorch神经网络都必须继承自一个基类: nn.Module\n",
    "2. 两个最重要的函数:\n",
    "    1. 构造函数 __init__ : 定义所有成员变量, 也就是网络结构\n",
    "    2. forward()函数: 定义网络的前向过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f5a5b1b8-e9c6-4d56-839b-f23754e8cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义网络\n",
    "class TestNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(784,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        B,C,W,H = x.shape\n",
    "        x = x.view(B,W*H)\n",
    "        return self.net(x)\n",
    "\n",
    "# 初始化网络\n",
    "model = TestNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e9fc2b6-9001-44f5-9cc1-1cf90cfbf165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 5.0412e-03, -5.2985e-03, -3.3600e-02,  ...,  2.6739e-02,\n",
       "          -1.2767e-02, -2.6027e-02],\n",
       "         [-3.4408e-03, -9.6523e-03, -1.8345e-02,  ...,  3.0322e-02,\n",
       "           1.9581e-02, -1.0461e-02],\n",
       "         [ 1.7202e-02,  3.0045e-02, -2.5928e-02,  ..., -2.4950e-02,\n",
       "           3.2066e-02,  1.7404e-02],\n",
       "         ...,\n",
       "         [ 1.2372e-02,  2.6555e-02,  1.5035e-02,  ..., -1.3219e-02,\n",
       "           7.5606e-03,  2.5888e-02],\n",
       "         [ 5.9575e-05, -1.2969e-03,  2.0245e-02,  ..., -1.2663e-02,\n",
       "          -1.1087e-04,  4.9757e-03],\n",
       "         [ 2.2977e-02, -1.6914e-02,  1.5477e-02,  ...,  3.2303e-02,\n",
       "           2.7043e-02, -1.9879e-02]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0061,  0.0253, -0.0056,  0.0139,  0.0051,  0.0211,  0.0136,  0.0338,\n",
       "         -0.0059,  0.0026, -0.0187,  0.0212, -0.0073,  0.0172, -0.0085, -0.0333,\n",
       "          0.0143, -0.0036, -0.0168, -0.0331, -0.0320, -0.0275, -0.0053,  0.0060,\n",
       "         -0.0155, -0.0129, -0.0050, -0.0073,  0.0232,  0.0324, -0.0057,  0.0113,\n",
       "          0.0047,  0.0224,  0.0258, -0.0135, -0.0204, -0.0250, -0.0050,  0.0313,\n",
       "          0.0313, -0.0129,  0.0249, -0.0272,  0.0141,  0.0206,  0.0043, -0.0165,\n",
       "          0.0100,  0.0023, -0.0024,  0.0046, -0.0105, -0.0200, -0.0350, -0.0320,\n",
       "         -0.0212, -0.0302,  0.0033, -0.0088,  0.0245, -0.0027,  0.0106,  0.0172,\n",
       "         -0.0062, -0.0352,  0.0196, -0.0226, -0.0297,  0.0227, -0.0219, -0.0115,\n",
       "         -0.0218, -0.0010,  0.0275, -0.0289, -0.0216, -0.0019,  0.0094,  0.0227,\n",
       "          0.0324,  0.0033,  0.0125, -0.0309, -0.0232, -0.0035,  0.0023, -0.0158,\n",
       "          0.0086,  0.0267, -0.0224,  0.0260, -0.0140,  0.0277,  0.0106, -0.0050,\n",
       "         -0.0181, -0.0051, -0.0219,  0.0076,  0.0037, -0.0039, -0.0084, -0.0058,\n",
       "         -0.0215, -0.0198, -0.0244, -0.0017,  0.0216, -0.0106,  0.0229, -0.0301,\n",
       "         -0.0170,  0.0093, -0.0286,  0.0082,  0.0165, -0.0337,  0.0217,  0.0101,\n",
       "          0.0175,  0.0154,  0.0196, -0.0076,  0.0200,  0.0305,  0.0357, -0.0010,\n",
       "          0.0151,  0.0084,  0.0153, -0.0270, -0.0124,  0.0104, -0.0177, -0.0154,\n",
       "          0.0052, -0.0210, -0.0182, -0.0257, -0.0262, -0.0085,  0.0089,  0.0211,\n",
       "          0.0113,  0.0157, -0.0282,  0.0069,  0.0077, -0.0242,  0.0214,  0.0092,\n",
       "         -0.0136,  0.0047, -0.0022, -0.0001,  0.0225,  0.0216,  0.0054, -0.0267,\n",
       "         -0.0138,  0.0278, -0.0090,  0.0331,  0.0029, -0.0265, -0.0168,  0.0136,\n",
       "         -0.0329,  0.0178,  0.0206,  0.0215, -0.0013, -0.0280,  0.0087,  0.0318,\n",
       "         -0.0267,  0.0170,  0.0142, -0.0332,  0.0283, -0.0197, -0.0064,  0.0205,\n",
       "          0.0083,  0.0278, -0.0013, -0.0161, -0.0326, -0.0069, -0.0182, -0.0273,\n",
       "         -0.0273,  0.0077,  0.0017,  0.0155, -0.0317, -0.0288, -0.0230, -0.0042,\n",
       "          0.0079, -0.0132, -0.0270,  0.0179,  0.0290, -0.0343,  0.0265,  0.0090,\n",
       "          0.0128,  0.0016,  0.0317,  0.0289, -0.0137,  0.0106, -0.0315, -0.0318,\n",
       "         -0.0240, -0.0115, -0.0080, -0.0135,  0.0082,  0.0188,  0.0351,  0.0028,\n",
       "         -0.0119, -0.0353,  0.0329, -0.0239,  0.0158, -0.0142, -0.0193,  0.0097,\n",
       "          0.0028, -0.0159, -0.0346,  0.0016, -0.0197, -0.0313,  0.0184,  0.0169,\n",
       "         -0.0125, -0.0095, -0.0006, -0.0060,  0.0077, -0.0232, -0.0225, -0.0196,\n",
       "         -0.0163, -0.0111, -0.0115, -0.0195,  0.0181, -0.0002,  0.0185, -0.0354],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0089, -0.0338,  0.0398,  ...,  0.0171, -0.0298,  0.0116],\n",
       "         [ 0.0216,  0.0617,  0.0336,  ..., -0.0421, -0.0129,  0.0410],\n",
       "         [-0.0224,  0.0597,  0.0556,  ..., -0.0560, -0.0474,  0.0371],\n",
       "         ...,\n",
       "         [-0.0118, -0.0540,  0.0094,  ..., -0.0435,  0.0013, -0.0413],\n",
       "         [ 0.0441, -0.0314, -0.0335,  ...,  0.0020, -0.0054,  0.0323],\n",
       "         [ 0.0524, -0.0561, -0.0040,  ..., -0.0572, -0.0065, -0.0098]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0472,  0.0083,  0.0541, -0.0315, -0.0064, -0.0489, -0.0070, -0.0539,\n",
       "          0.0229,  0.0101, -0.0233, -0.0125,  0.0121,  0.0470, -0.0107,  0.0554,\n",
       "         -0.0006,  0.0040, -0.0417,  0.0402, -0.0432, -0.0560,  0.0160, -0.0152,\n",
       "         -0.0377, -0.0159, -0.0498,  0.0495,  0.0346, -0.0240, -0.0416,  0.0005,\n",
       "          0.0426,  0.0263, -0.0570,  0.0148, -0.0611, -0.0235, -0.0250, -0.0493,\n",
       "          0.0036, -0.0120,  0.0209, -0.0389, -0.0190, -0.0392,  0.0339, -0.0454,\n",
       "         -0.0153,  0.0366, -0.0416, -0.0196, -0.0350,  0.0602, -0.0571, -0.0615,\n",
       "         -0.0611, -0.0230, -0.0055,  0.0396,  0.0032,  0.0593,  0.0371,  0.0428,\n",
       "         -0.0461, -0.0287,  0.0537, -0.0389,  0.0491, -0.0233,  0.0008,  0.0104,\n",
       "         -0.0572,  0.0600,  0.0080, -0.0241, -0.0108,  0.0578,  0.0344,  0.0554,\n",
       "          0.0598, -0.0427,  0.0441,  0.0196,  0.0547, -0.0392,  0.0567,  0.0341,\n",
       "          0.0188, -0.0150, -0.0167, -0.0290,  0.0415,  0.0192, -0.0516, -0.0073,\n",
       "          0.0147,  0.0238,  0.0213, -0.0361, -0.0040,  0.0111, -0.0304, -0.0261,\n",
       "          0.0529, -0.0363,  0.0289, -0.0134,  0.0099,  0.0495,  0.0485,  0.0133,\n",
       "         -0.0473,  0.0484, -0.0225,  0.0112,  0.0491, -0.0567,  0.0175,  0.0580,\n",
       "         -0.0278,  0.0106, -0.0478,  0.0055, -0.0007,  0.0262,  0.0413,  0.0199,\n",
       "          0.0013,  0.0364,  0.0602,  0.0233,  0.0461, -0.0255, -0.0325,  0.0009,\n",
       "          0.0068,  0.0578, -0.0263,  0.0451,  0.0199, -0.0572,  0.0621,  0.0004,\n",
       "         -0.0464, -0.0497,  0.0596,  0.0448,  0.0542, -0.0343,  0.0353, -0.0341,\n",
       "          0.0556, -0.0054, -0.0553, -0.0461, -0.0217, -0.0232, -0.0438, -0.0100,\n",
       "         -0.0594, -0.0017, -0.0451, -0.0293,  0.0127,  0.0097,  0.0252,  0.0428,\n",
       "          0.0291,  0.0191,  0.0129,  0.0406,  0.0359, -0.0146, -0.0475,  0.0142,\n",
       "         -0.0147, -0.0257,  0.0479,  0.0250, -0.0363, -0.0019, -0.0417,  0.0289,\n",
       "          0.0220, -0.0180, -0.0308,  0.0500, -0.0121,  0.0579,  0.0149,  0.0485,\n",
       "         -0.0509,  0.0063,  0.0624, -0.0540, -0.0032,  0.0042, -0.0510,  0.0182,\n",
       "         -0.0432,  0.0584, -0.0603,  0.0364, -0.0049,  0.0098, -0.0583, -0.0280,\n",
       "          0.0543, -0.0023,  0.0396,  0.0117,  0.0137,  0.0285, -0.0111, -0.0029,\n",
       "         -0.0289,  0.0009,  0.0122,  0.0144,  0.0250, -0.0318, -0.0341, -0.0023,\n",
       "          0.0364,  0.0349,  0.0005,  0.0592,  0.0175,  0.0180, -0.0012, -0.0379,\n",
       "         -0.0064,  0.0024, -0.0123,  0.0534,  0.0586,  0.0252,  0.0021,  0.0078,\n",
       "         -0.0603,  0.0278,  0.0166, -0.0538,  0.0203, -0.0508, -0.0361,  0.0004,\n",
       "         -0.0356, -0.0198, -0.0446,  0.0497,  0.0043, -0.0542,  0.0365, -0.0393],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0527,  0.0226,  0.0072,  ...,  0.0224,  0.0486, -0.0524],\n",
       "         [ 0.0112,  0.0267,  0.0111,  ...,  0.0124, -0.0293,  0.0494],\n",
       "         [ 0.0192,  0.0405, -0.0533,  ..., -0.0127, -0.0588,  0.0274],\n",
       "         ...,\n",
       "         [-0.0204,  0.0064, -0.0617,  ..., -0.0271, -0.0010,  0.0588],\n",
       "         [-0.0485,  0.0096, -0.0383,  ..., -0.0068,  0.0345,  0.0008],\n",
       "         [-0.0102, -0.0508,  0.0393,  ..., -0.0044, -0.0009,  0.0156]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0424,  0.0601,  0.0174, -0.0494,  0.0266,  0.0021,  0.0077,  0.0411,\n",
       "          0.0434, -0.0134], device='cuda:0', requires_grad=True)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c87274-8441-443d-ab97-e5a9bf832837",
   "metadata": {},
   "source": [
    "## 基本组件2: 优化器\n",
    "1. 优化器一般不用自己写, 通常继承自: torch.optim.Optimizer\n",
    "2. 优化器的构造函数中必须定义该优化器对应的可优化参数\n",
    "3. 例如learning rate, weight decay, momentum 之类的都是不同优化器的可调节参数，这些参数对最终模型的性能影响非常大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "362c1974-81d3-4172-a0f0-347ab8a98b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446c848-f5b9-4923-bae4-02d0b6e4e733",
   "metadata": {},
   "source": [
    "## 基本组件3: 损失函数\n",
    "1. 损失函数可以自己任意定义，一般来说输出是一个标量的损失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4585767e-2609-42cd-a3a4-0104efe50321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f785c-3661-4be1-91c6-c05947e029fd",
   "metadata": {},
   "source": [
    "## 定义训练函数\n",
    "有了上述三个组件，我们就可以定义训练过程了，在很多框架中，下面的这个函数被称为trainer\n",
    "\n",
    "trainer 定义了训练中一个完整的正向、反向传播过程\n",
    "\n",
    "trainer 不一定有返回值,一般会返回loss的数值进行可视化，在这个过程中，重要的是model这个对象的所有参数获得了更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "023a8fe6-f436-4597-9cbc-64bc97c7aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意loss_func不一定通过传参形式给到trainer, 可以直接import\n",
    "# device 是CPU或CUDA, 或者特定编号的GPU\n",
    "def trainer(batch, model, optimizer, loss_func, device):\n",
    "    # 将模型参数设为训练模式\n",
    "    model.train()\n",
    "    # 从batch中获取输入数据和标签(不一定有标签)\n",
    "    x, y = batch\n",
    "    # 将数据存入对应设备中\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    # 梯度清零\n",
    "    optimizer.zero_grad()\n",
    "    # 前向传播\n",
    "    y_hat = model(x)\n",
    "    # 计算loss\n",
    "    loss = loss_func(y_hat,y)\n",
    "    # 反向传播获取梯度\n",
    "    loss.backward()\n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "\n",
    "    # 计算准确率\n",
    "    predictions = torch.argmax(y_hat, dim=1)  # 获取模型的预测结果\n",
    "    correct_predictions = (predictions == y).sum().item()  # 统计正确的预测数量\n",
    "    return loss.item() / y.shape[0], correct_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "293aadb4-0eb8-4e3a-b005-b8d0b94496bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randint(0,10,(32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d55b9cf1-32b1-4915-b925-a079e36b2a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a6a97a6c-14d5-41c2-932b-b0a5c80f39e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32,1,28,28).cuda()\n",
    "y_hat = model(x)\n",
    "loss = y_hat.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c7aafdb8-25e0-4770-a7ce-95ca591e69ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 5.0412e-03, -5.2985e-03, -3.3600e-02,  ...,  2.6739e-02,\n",
       "         -1.2767e-02, -2.6027e-02],\n",
       "        [-3.4408e-03, -9.6523e-03, -1.8345e-02,  ...,  3.0322e-02,\n",
       "          1.9581e-02, -1.0461e-02],\n",
       "        [ 1.7202e-02,  3.0045e-02, -2.5928e-02,  ..., -2.4950e-02,\n",
       "          3.2066e-02,  1.7404e-02],\n",
       "        ...,\n",
       "        [ 1.2372e-02,  2.6555e-02,  1.5035e-02,  ..., -1.3219e-02,\n",
       "          7.5606e-03,  2.5888e-02],\n",
       "        [ 5.9575e-05, -1.2969e-03,  2.0245e-02,  ..., -1.2663e-02,\n",
       "         -1.1087e-04,  4.9757e-03],\n",
       "        [ 2.2977e-02, -1.6914e-02,  1.5477e-02,  ...,  3.2303e-02,\n",
       "          2.7043e-02, -1.9879e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "687dc43e-f270-4ee2-a031-52d754390456",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "aeb0b42d-d7f4-4d8e-8849-8e3a811c1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa343914-8c22-418a-9f2f-a2bbd6565351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0040, -0.0043, -0.0326,  ...,  0.0257, -0.0118, -0.0250],\n",
       "        [-0.0044, -0.0107, -0.0193,  ...,  0.0313,  0.0186, -0.0095],\n",
       "        [ 0.0162,  0.0310, -0.0269,  ..., -0.0239,  0.0331,  0.0164],\n",
       "        ...,\n",
       "        [ 0.0134,  0.0256,  0.0160,  ..., -0.0122,  0.0086,  0.0249],\n",
       "        [ 0.0011, -0.0003,  0.0212,  ..., -0.0117,  0.0009,  0.0040],\n",
       "        [ 0.0240, -0.0159,  0.0145,  ...,  0.0313,  0.0260, -0.0189]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aca094-99f8-4d6d-bc9c-6d6c2f3f2a66",
   "metadata": {},
   "source": [
    "## 定义验证函数\n",
    "1. 验证函数需要将模型设置为预测模式\n",
    "2. 需要输入validation loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a0de5adb-1f7e-4e8f-9057-aa99c8f550ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, loss_func, device):\n",
    "    # 将模型参数设为评估模式\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for batch in val_loader:\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # 前向传播\n",
    "            y_hat = model(x)\n",
    "            # 计算loss\n",
    "            loss = loss_func(y_hat, y)\n",
    "\n",
    "            total_loss += loss.item() / y.size(0)\n",
    "\n",
    "            # 计算准确率\n",
    "            predictions = torch.argmax(y_hat, dim=1)\n",
    "            correct_predictions += (predictions == y).sum().item()\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    # 计算平均损失和准确率\n",
    "    average_loss = total_loss / len(val_loader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Validation Loss: {average_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    return average_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a34964-8199-4fe2-91e8-4453904617d3",
   "metadata": {},
   "source": [
    "## 输入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbb5f0-d122-48cd-accd-587d662480bf",
   "metadata": {},
   "source": [
    "## 数据集\n",
    "1. 数据集通常继承自: torch.utils.data.Dataset 基类\n",
    "2. 对于图像中的常用数据集, 一般会在torchvision库中有定义好的Dataset类\n",
    "3. 对于不常用的数据集，往往需要手写Dataset类, 手写Dataset类时一定需要的是__getitem__方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2136d1a7-d087-48b9-b61f-7d9444415ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# 定义数据集的转换\n",
    "my_transform = T.Compose([\n",
    "    T.ToTensor(),  # 将图像转换为张量\n",
    "    T.Normalize((0.5,), (0.5,))  # 标准化张量，使其范围在[-1, 1]之间\n",
    "])\n",
    "\n",
    "# 初始化训练集和测试集\n",
    "train_dataset = MNIST(root='./data', train=True, transform=my_transform, download=True)\n",
    "test_dataset = MNIST(root='./data', train=False, transform=my_transform, download=True)\n",
    "\n",
    "# 自定义数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, transform):\n",
    "        super().__init__()\n",
    "        self.data = [0 for i in range(100)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transform(self.data[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea8368-6fd8-4fb4-b64b-f56aa4438f48",
   "metadata": {},
   "source": [
    "## 数据读取\n",
    "1. DataLoader可以从数据集中读取不同batch的数据，可以通过定义num_workers来定义数据读取线程的数量, 通过pin_memory来决定数据是否要存放在内存条中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "98d4be2a-09a8-4e5a-a71c-e9f72187f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义 DataLoader 来加载数据\n",
    "batch_size = 512\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45202aeb-af5e-4134-9460-ad150a9f79ef",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976de4a0-5b14-4a6e-a655-f7b787f92e16",
   "metadata": {},
   "source": [
    "## 结果输出\n",
    "1. 可以输出到txt文件\n",
    "2. 直接使用print\n",
    "3. 使用tensorboard等工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5da09a1-32bf-4587-80e1-fcb2c7f9b7b1",
   "metadata": {},
   "source": [
    "# Tips\n",
    "1. 代码需要遵循“高内聚，低耦合”的设计思路，既每个函数、每个类都只完成最少的任务，这样才方便修改，快速移植\n",
    "2. 善于组合别人的代码，将别人的模块化用到自己的代码中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "abb20f54-95b4-4a94-bfa1-629c61a5bad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Training Loss: 0.0016 | Accuracy: 81.53%\n",
      "Epoch: 1 Training Loss: 0.0007 | Accuracy: 93.25%\n",
      "Epoch: 2 Training Loss: 0.0005 | Accuracy: 95.18%\n",
      "Epoch: 3 Training Loss: 0.0004 | Accuracy: 96.37%\n",
      "Epoch: 4 Training Loss: 0.0003 | Accuracy: 97.11%\n",
      "Validation Loss: 0.0003 | Accuracy: 97.03%\n",
      "Epoch: 5 Training Loss: 0.0003 | Accuracy: 97.66%\n",
      "Epoch: 6 Training Loss: 0.0002 | Accuracy: 98.09%\n",
      "Epoch: 7 Training Loss: 0.0002 | Accuracy: 98.44%\n",
      "Epoch: 8 Training Loss: 0.0002 | Accuracy: 98.70%\n",
      "Epoch: 9 Training Loss: 0.0001 | Accuracy: 98.90%\n",
      "Validation Loss: 0.0002 | Accuracy: 98.00%\n",
      "Epoch: 10 Training Loss: 0.0001 | Accuracy: 99.12%\n",
      "Epoch: 11 Training Loss: 0.0001 | Accuracy: 99.27%\n",
      "Epoch: 12 Training Loss: 0.0001 | Accuracy: 99.45%\n",
      "Epoch: 13 Training Loss: 0.0001 | Accuracy: 99.59%\n",
      "Epoch: 14 Training Loss: 0.0001 | Accuracy: 99.66%\n",
      "Validation Loss: 0.0002 | Accuracy: 98.18%\n",
      "Epoch: 15 Training Loss: 0.0001 | Accuracy: 99.77%\n",
      "Epoch: 16 Training Loss: 0.0000 | Accuracy: 99.80%\n",
      "Epoch: 17 Training Loss: 0.0000 | Accuracy: 99.84%\n",
      "Epoch: 18 Training Loss: 0.0000 | Accuracy: 99.88%\n",
      "Epoch: 19 Training Loss: 0.0000 | Accuracy: 99.90%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.08%\n",
      "Epoch: 20 Training Loss: 0.0000 | Accuracy: 99.94%\n",
      "Epoch: 21 Training Loss: 0.0000 | Accuracy: 99.95%\n",
      "Epoch: 22 Training Loss: 0.0000 | Accuracy: 99.97%\n",
      "Epoch: 23 Training Loss: 0.0000 | Accuracy: 99.97%\n",
      "Epoch: 24 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.04%\n",
      "Epoch: 25 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Epoch: 26 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Epoch: 27 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Epoch: 28 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Epoch: 29 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.20%\n",
      "Epoch: 30 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Epoch: 31 Training Loss: 0.0000 | Accuracy: 99.91%\n",
      "Epoch: 32 Training Loss: 0.0000 | Accuracy: 99.92%\n",
      "Epoch: 33 Training Loss: 0.0000 | Accuracy: 99.94%\n",
      "Epoch: 34 Training Loss: 0.0000 | Accuracy: 99.94%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.05%\n",
      "Epoch: 35 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Epoch: 36 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Epoch: 37 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 38 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 39 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.36%\n",
      "Epoch: 40 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 41 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 42 Training Loss: 0.0000 | Accuracy: 99.80%\n",
      "Epoch: 43 Training Loss: 0.0001 | Accuracy: 99.20%\n",
      "Epoch: 44 Training Loss: 0.0000 | Accuracy: 99.77%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.17%\n",
      "Epoch: 45 Training Loss: 0.0000 | Accuracy: 99.94%\n",
      "Epoch: 46 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Epoch: 47 Training Loss: 0.0000 | Accuracy: 99.98%\n",
      "Epoch: 48 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 49 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.56%\n",
      "Epoch: 50 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 51 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 52 Training Loss: 0.0000 | Accuracy: 99.97%\n",
      "Epoch: 53 Training Loss: 0.0000 | Accuracy: 99.64%\n",
      "Epoch: 54 Training Loss: 0.0000 | Accuracy: 99.66%\n",
      "Validation Loss: 0.0002 | Accuracy: 97.72%\n",
      "Epoch: 55 Training Loss: 0.0000 | Accuracy: 99.96%\n",
      "Epoch: 56 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Epoch: 57 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Epoch: 58 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 59 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.55%\n",
      "Epoch: 60 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 61 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 62 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 63 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 64 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.57%\n",
      "Epoch: 65 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 66 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 67 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 68 Training Loss: 0.0000 | Accuracy: 99.90%\n",
      "Epoch: 69 Training Loss: 0.0001 | Accuracy: 99.02%\n",
      "Validation Loss: 0.0002 | Accuracy: 97.38%\n",
      "Epoch: 70 Training Loss: 0.0000 | Accuracy: 99.64%\n",
      "Epoch: 71 Training Loss: 0.0000 | Accuracy: 99.92%\n",
      "Epoch: 72 Training Loss: 0.0000 | Accuracy: 99.95%\n",
      "Epoch: 73 Training Loss: 0.0000 | Accuracy: 99.95%\n",
      "Epoch: 74 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.52%\n",
      "Epoch: 75 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 76 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 77 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 78 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Epoch: 79 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.54%\n",
      "Epoch: 80 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 81 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 82 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 83 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 84 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.61%\n",
      "Epoch: 85 Training Loss: 0.0000 | Accuracy: 99.97%\n",
      "Epoch: 86 Training Loss: 0.0000 | Accuracy: 99.41%\n",
      "Epoch: 87 Training Loss: 0.0000 | Accuracy: 99.61%\n",
      "Epoch: 88 Training Loss: 0.0000 | Accuracy: 99.91%\n",
      "Epoch: 89 Training Loss: 0.0000 | Accuracy: 99.99%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.32%\n",
      "Epoch: 90 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 91 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 92 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 93 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Epoch: 94 Training Loss: 0.0000 | Accuracy: 100.00%\n",
      "Validation Loss: 0.0001 | Accuracy: 98.29%\n",
      "Epoch: 95 Training Loss: 0.0000 | Accuracy: 99.95%\n",
      "Epoch: 96 Training Loss: 0.0000 | Accuracy: 99.97%\n",
      "Epoch: 97 Training Loss: 0.0000 | Accuracy: 99.89%\n",
      "Epoch: 98 Training Loss: 0.0000 | Accuracy: 99.76%\n",
      "Epoch: 99 Training Loss: 0.0000 | Accuracy: 99.85%\n",
      "Validation Loss: 0.0002 | Accuracy: 98.06%\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "total_ep = 100\n",
    "for ep in range(total_ep):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for batch in train_loader:\n",
    "        loss, correct_predictions = trainer(batch, model, optimizer, loss_func, device)\n",
    "        total_loss += loss\n",
    "        total_correct += correct_predictions\n",
    "        total_samples += batch[1].shape[0]\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Epoch: {ep} Training Loss: {average_loss:.4f} | Accuracy: {accuracy * 100:.2f}%\")\n",
    "        \n",
    "    if (ep+1) % 5 == 0:\n",
    "        validate(test_loader, model, loss_func, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
